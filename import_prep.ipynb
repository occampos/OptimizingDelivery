{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptimizingDelivery Import and Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r optimizingdelivery_source_dir\n",
    "%store -r optimizingdelivery_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of file names\n",
    "file_names = ['dim_customers.csv', \n",
    "              'dim_date.csv', \n",
    "              'dim_products.csv', \n",
    "              'dim_targets_orders.csv', \n",
    "              'fact_order_lines.csv', \n",
    "              'fact_orders_aggregate.csv']\n",
    "\n",
    "# Read each CSV file into a pandas DataFrame\n",
    "og_dataframes = [pd.read_csv(os.path.join(optimizingdelivery_source_dir, file)) for file in file_names]\n",
    "\n",
    "# Unpack the list of DataFrames into individual variables\n",
    "customers, all_dates, products, target_orders, order_lines, orders_aggregate = og_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 3)\n",
      "(183, 3)\n",
      "(18, 3)\n",
      "(35, 4)\n",
      "(57096, 11)\n",
      "(31729, 6)\n"
     ]
    }
   ],
   "source": [
    "print(customers.shape)\n",
    "print(all_dates.shape)\n",
    "print(products.shape)\n",
    "print(target_orders.shape)\n",
    "print(order_lines.shape)\n",
    "print(orders_aggregate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates and nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframes and dataframe names\n",
    "dataframes = [customers, all_dates, products, target_orders, order_lines, orders_aggregate]\n",
    "dataframe_names = ['customers', 'all_dates', 'products', 'target_orders', 'order_lines', 'orders_aggregate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers:\n",
      "none\n",
      "all_dates:\n",
      "none\n",
      "products:\n",
      "none\n",
      "target_orders:\n",
      "none\n",
      "order_lines:\n",
      "none\n",
      "orders_aggregate:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# Check dataframes for duplicate rows\n",
    "\n",
    "# Define function to check for duplicate rows\n",
    "def check_dupe(dataframe_names, dataframes):\n",
    "\n",
    "    # Loop through each dataframe\n",
    "    for df_name, df in zip(dataframe_names, dataframes):\n",
    "\n",
    "        # Find duplicate rows\n",
    "        duplicates = df[df.duplicated()]\n",
    "\n",
    "        # Yield the dataframe name and duplicated rows\n",
    "        yield df_name, duplicates if not duplicates.empty else pd.DataFrame()\n",
    "\n",
    "# Output the duplicate rows for each dataframe\n",
    "for df_name, duplicates in check_dupe(dataframe_names, dataframes):\n",
    "    \n",
    "    # Print \n",
    "    print(f\"{df_name}:\")\n",
    "    if not duplicates.empty:\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(\"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers:\n",
      "none\n",
      "all_dates:\n",
      "none\n",
      "products:\n",
      "none\n",
      "target_orders:\n",
      "none\n",
      "order_lines:\n",
      "none\n",
      "orders_aggregate:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# Check dataframes for nan rows\n",
    "\n",
    "# Define function to check for nan rows\n",
    "def check_nan(dataframe_names, dataframes):\n",
    "\n",
    "    # Loop through each dataframe\n",
    "    for df_name, df in zip(dataframe_names, dataframes):\n",
    "\n",
    "        # Find rows with nan values\n",
    "        nan_rows = df[df.isnull().any(axis=1)]\n",
    "\n",
    "        # Yield the dataframe name and rows with nan values\n",
    "        yield df_name, nan_rows if not nan_rows.empty else None\n",
    "\n",
    "# Output the rows with nan values for each dataframe or output none\n",
    "for df_name, nan_rows in check_nan(dataframe_names, dataframes):\n",
    "\n",
    "    # Print \n",
    "    print(f\"{df_name}:\")\n",
    "    if nan_rows is not None:\n",
    "        print(nan_rows)\n",
    "    else:\n",
    "        print(\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id       int64\n",
       "customer_name    object\n",
       "city             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dates dataframe so it encompasses all of 2022\n",
    "dates_2022 = pd.DataFrame({'date': pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')})\n",
    "\n",
    "# Week number in source data is 8 days ahead of default week numbers\n",
    "# Make sure new week number matchs with source data, testing with 'boingo'\n",
    "dates_2022['boingo'] = dates_2022['date'].dt.isocalendar().week.shift(-8)\n",
    "\n",
    "# Fill in nans from shifting\n",
    "dates_2022.loc[dates_2022.index == 357, 'boingo'] = 52\n",
    "dates_2022.loc[dates_2022.index > 357, 'boingo'] = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all rows match\n"
     ]
    }
   ],
   "source": [
    "# Merge dataframes to check new column matches source\n",
    "\n",
    "# prepare source for merge\n",
    "all_dates['date'] = pd.to_datetime(all_dates['date'], format='%d-%b-%y')\n",
    "all_dates['week_number'] = all_dates['week_no'].str.split().str[1].astype(int)\n",
    "\n",
    "# Merge\n",
    "merge = pd.merge(all_dates, dates_2022, how='left', on='date')\n",
    "\n",
    "# Output whether rows match\n",
    "if len(merge[~(merge['week_number'] == merge['boingo'])]) == 0:\n",
    "    print(\"all rows match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns\n",
    "dates_2022['month'] = dates_2022['date'].dt.month.astype('int64')\n",
    "dates_2022['day'] = dates_2022['date'].dt.day.astype('int64')\n",
    "dates_2022['week_number'] = dates_2022['boingo'].astype('int64')\n",
    "\n",
    "# Reorder columns\n",
    "dates_2022 = dates_2022[['date', 'month', 'day', 'week_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           datetime64[ns]\n",
       "month                   int64\n",
       "day                     int64\n",
       "week_number             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_2022.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name    object\n",
       "product_id       int64\n",
       "category        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### target_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id       int64\n",
       "ontime_target%    int64\n",
       "infull_target%    int64\n",
       "otif_target%      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_orders.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### order_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                object\n",
       "order_placement_date    object\n",
       "customer_id              int64\n",
       "product_id               int64\n",
       "order_qty                int64\n",
       "agreed_delivery_date    object\n",
       "actual_delivery_date    object\n",
       "delivery_qty             int64\n",
       "In Full                  int64\n",
       "On Time                  int64\n",
       "On Time In Full          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_lines.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatypes\n",
    "order_lines['order_placement_date'] = pd.to_datetime(order_lines['order_placement_date'], format='%A, %B %d, %Y')\n",
    "order_lines['agreed_delivery_date'] = pd.to_datetime(order_lines['agreed_delivery_date'], format='%A, %B %d, %Y')\n",
    "order_lines['actual_delivery_date'] = pd.to_datetime(order_lines['actual_delivery_date'], format='%A, %B %d, %Y')\n",
    "\n",
    "# Sort dataframe by date increasing\n",
    "order_lines = order_lines.sort_values('order_placement_date').reset_index(drop=True)\n",
    "\n",
    "# Rename columns\n",
    "order_lines = order_lines.rename(columns={\n",
    "                                          'In Full': 'in_full',\n",
    "                                          'On Time': 'on_time',\n",
    "                                          'On Time In Full': 'on_time_in_full'\n",
    "})\n",
    "\n",
    "# Reorder columns\n",
    "order_lines = order_lines[['order_id', 'order_placement_date', 'customer_id', 'product_id',\n",
    "       'order_qty', 'agreed_delivery_date', 'actual_delivery_date',\n",
    "       'delivery_qty', 'in_full', 'on_time', 'on_time_in_full']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                        object\n",
       "order_placement_date    datetime64[ns]\n",
       "customer_id                      int64\n",
       "product_id                       int64\n",
       "order_qty                        int64\n",
       "agreed_delivery_date    datetime64[ns]\n",
       "actual_delivery_date    datetime64[ns]\n",
       "delivery_qty                     int64\n",
       "in_full                          int64\n",
       "on_time                          int64\n",
       "on_time_in_full                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_lines.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### orders_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                object\n",
       "customer_id              int64\n",
       "order_placement_date    object\n",
       "on_time                  int64\n",
       "in_full                  int64\n",
       "otif                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_aggregate.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_aggregate['order_placement_date'] = pd.to_datetime(orders_aggregate['order_placement_date'], format='%d-%b-%y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                        object\n",
       "customer_id                      int64\n",
       "order_placement_date    datetime64[ns]\n",
       "on_time                          int64\n",
       "in_full                          int64\n",
       "otif                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_aggregate.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared data to parquet files\n",
    "\n",
    "# Define dataframes and dataframe names\n",
    "dataframes = [customers, dates_2022, products, target_orders, order_lines, orders_aggregate]\n",
    "dataframe_names = ['customers', 'dates_2022', 'products', 'target_orders', 'order_lines', 'orders_aggregate']\n",
    "\n",
    "# Iterate over dataframes and names\n",
    "for dataframe, name in zip(dataframes, dataframe_names):\n",
    "\n",
    "    # Create file paths\n",
    "    file_path = os.path.join(optimizingdelivery_data_dir, f\"{name}.parquet\")\n",
    "    \n",
    "    # Save the dataframes\n",
    "    dataframe.to_parquet(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
